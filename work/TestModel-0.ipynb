{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import keras\n",
    "    \n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import History \n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import skimage.data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "import mountainproject as mp\n",
    "\n",
    "from importlib import reload\n",
    "reload(mp)\n",
    "\n",
    "# Allow image embeding in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--modeldir', '-d')\n",
    "parser.add_argument('--imagefile', '-f')\n",
    "parser.add_argument('--learningrate', '-l', default=1e-6)\n",
    "parser.add_argument('--opt', '-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().__class__.__name__\n",
    "    args = parser.parse_args(['-d', '21stStreet-Adam-4986-200x200-6', \n",
    "                              '-f', 'testimages/20180110_100024.jpg'\n",
    "                             ]\n",
    "                            )\n",
    "    in_jupyter = True\n",
    "    print('In Jupyter...')\n",
    "except:\n",
    "    args = parser.parse_args()\n",
    "    in_jupyter = False\n",
    "    print('NOT in Jupyter...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir  = args.modeldir\n",
    "image_file = args.imagefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, opt, num_images, image_size, unique_id = model_dir.split('-')\n",
    "width, height = image_size.split('x')\n",
    "width = int(width)\n",
    "height = int(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_devices=True\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_path = os.path.join(save_dir, model_dir)\n",
    "\n",
    "#... Load model and weights\n",
    "model = load_model(os.path.join(model_path, 'model.h5'))\n",
    "print('Loaded trained model from %s ' % model_path)\n",
    "\n",
    "#... Load history\n",
    "with open(os.path.join(model_path, 'history.pk'), 'rb') as f:\n",
    "    hist = pickle.load(f)\n",
    "print('Loaded history...')\n",
    "\n",
    "#... Load epoch times\n",
    "with open(os.path.join(model_path, 'times.pk'), 'rb') as f:\n",
    "    times = pickle.load(f)\n",
    "print('Loaded times...')\n",
    "\n",
    "#... Score trained model.\n",
    "with open(os.path.join(model_path, 'eval.pk'), 'rb') as f:\n",
    "    eval_scores = pickle.load(f)\n",
    "print('Loaded model evals...')\n",
    "\n",
    "with open(os.path.join(model_path, 'pred.pk'), 'rb') as f:\n",
    "    pred = pickle.load(f)\n",
    "print('Loaded model predictions...')\n",
    "\n",
    "with open(os.path.join(model_path, 'label_map.pk'), 'rb') as f:\n",
    "    label_map = pickle.load(f)\n",
    "label_map = {v: k for k, v in label_map.items()}\n",
    "print('Loaded label map...')\n",
    "\n",
    "# print('Test loss:', scores[0])\n",
    "# print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cwd = os.getcwd()\n",
    "# save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# model_path = os.path.join(save_dir, model_dir)\n",
    "\n",
    "# model = load_model(os.path.join(model_path, 'cifar10_normal_rms_ep125.h5'))\n",
    "# print('Loaded trained model from %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_jupyter:\n",
    "\n",
    "    #... Plot the Loss Curves\n",
    "    plt.figure(figsize=[8,6])\n",
    "    plt.plot(hist['loss'],'r',linewidth=3.0)\n",
    "    plt.plot(hist['val_loss'],'b',linewidth=3.0)\n",
    "    plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "    plt.xlabel('Epochs ',fontsize=16)\n",
    "    plt.ylabel('Loss',fontsize=16)\n",
    "    plt.title('Loss Curves',fontsize=16)\n",
    "\n",
    "    #Plot the Accuracy Curves\n",
    "    plt.figure(figsize=[8,6])\n",
    "    plt.plot(hist['acc'],'r',linewidth=3.0)\n",
    "    plt.plot(hist['val_acc'],'b',linewidth=3.0)\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "    plt.xlabel('Epochs ',fontsize=16)\n",
    "    plt.ylabel('Accuracy',fontsize=16)\n",
    "    plt.title('Accuracy Curves',fontsize=16)\n",
    "\n",
    "#     sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_file = './bogusimages/aviation.jpg'\n",
    "# image_file = './bogusimages/tulips.jpg'\n",
    "# image_file = './testimages/20180130_095954.jpg'\n",
    "# image_file = 'testimages/20180207_095919.jpg'\n",
    "# image_file = 'testimages/cat-0.jpg'\n",
    "# image_file = 'testimages/auto-2.jpg'\n",
    "# image_file = 'testimages/kagglecatsanddogs/PetImages/Cat/0.jpg'\n",
    "# image_file = 'data/gopro/21st-street/006-244W21/GOPR54152287.jpg'\n",
    "# image_file = 'data/gopro/21st-street/031-221W21/GOPR541515739.jpg'\n",
    "# image_file = 'data/gopro/21st-street/210W21/GOPR541523239.jpg'\n",
    "# image_file = 'data/android/21st-street/010-228W21/0000003339.jpg'\n",
    "# image_file = 'data/android/21st-street/026-2128thAve/0000006359.jpg'\n",
    "# image_file = 'data/gopro/21st-street/228W21/GOPR5415138.jpg'\n",
    "# image_file = 'data/android/21st-street/247W21/0000008524.jpg'\n",
    "# image_file = 'data/android/21st-street/243W21/0000009030.jpg'\n",
    "# image_file = 'data/android/21st-street/268W21/0000006023.jpg'\n",
    "# image_file = 'testimages/20180110_100207.jpg'\n",
    "# image_file = 'data/android/21st-street/unlabeled/0000000207.jpg'\n",
    "# image_file = 'data/android/21st-street/unlabeled/0000002140.jpg'\n",
    "# image_file = 'data/android/21st-street/trainval/validation/000-200W21/0000000547.jpg'\n",
    "# image_file = 'data/android/21st-street/trainval/validation/010-228W21/0000003325.jpg'\n",
    "\n",
    "# image_file = 'data/small/21st-street/200W21/0000000539.jpg'\n",
    "# image_file = 'data/small/21st-street/trainval/training/200W21/0000000577.jpg'\n",
    "# image_file = 'data/small/21st-street/trainval/validation/214W21/GOPR541523871.jpg'\n",
    "image_file = 'data/merged/21st-street/226W21/0000003152.jpg'\n",
    "\n",
    "# image = skimage.data.imread(image_file)\n",
    "# img = np.array( Image.fromarray(image, 'RGB').resize((width, height)) )\n",
    "\n",
    "# image = Image.open(image_file).rotate(-90)\n",
    "# image = Image.open(image_file)\n",
    "\n",
    "#... Use with 'testimages' (aka still photos taken with Android)\n",
    "# image = Image.open(image_file).convert(\"RGB\").rotate(-90).resize((width, height))\n",
    "# full_image = Image.open(image_file).convert(\"RGB\").rotate(-90)\n",
    "\n",
    "#... Use with images scraped from video (either GoPro or Android)\n",
    "image = Image.open(image_file).convert(\"RGB\").resize((width, height))\n",
    "# image = Image.open(image_file).resize((width, height))\n",
    "\n",
    "img = np.array(image)\n",
    "# img = img * 1./255.\n",
    "\n",
    "r = img[:,:,0]\n",
    "g = img[:,:,1]\n",
    "b = img[:,:,2]\n",
    "\n",
    "npimages = np.array([[r] + [g] + [b]], np.uint8)\n",
    "npimages = npimages.transpose(0,2,3,1)\n",
    "\n",
    "classes = model.predict_classes(npimages)\n",
    "prediction = model.predict(npimages, verbose=2)\n",
    "\n",
    "print(prediction.argmax())\n",
    "print(classes)\n",
    "print(label_map[classes[0]])\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = img / 255.\n",
    "x1 = x1 - x1.mean()\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = ((x/255.) - 0.5) * 2.\n",
    "\n",
    "x2 = ((img/255.) - 0.5) * 2.\n",
    "x2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "image_file = './testimages/20180110_100046.jpg'\n",
    "# image_file = 'data/android/21st-street/035-247W21/0000008524.jpg'\n",
    "# image_file = 'data/android/21st-street/unlabeled/0000002140.jpg'\n",
    "# image_file = 'data/android/21st-street/unlabeled/0000000207.jpg'\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "img = cv2.resize(image, (width, height), interpolation = cv2.INTER_AREA)\n",
    "img = np.array(img)\n",
    "\n",
    "r = img[:,:,2]\n",
    "g = img[:,:,1]\n",
    "b = img[:,:,0]\n",
    "\n",
    "npimage = np.array([[r] + [g] + [b]], np.uint8)\n",
    "npimage = npimage.transpose(0,2,3,1)\n",
    "\n",
    "classes = model.predict_classes(npimage)\n",
    "pred = model.predict(npimage, verbose=2)\n",
    "\n",
    "print(pred)\n",
    "print(classes)\n",
    "print(label_map[classes[0]])\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map = ['airplanes', 'cars', 'birds', 'cats', 'deer', 'dogs', 'frogs', 'horses', 'ships', 'trucks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model from /home/joeantol/joeantolwork/project-x/saved_models/21stStreet-Adam-4986-200x200-6 \n",
      "Loaded label map...\n",
      "Right = 14.000000000000002\n",
      "Wrong = 86.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import keras\n",
    "    \n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "image_dir = 'data/merged/21st-street/'\n",
    "model_dir = '21stStreet-Adam-4986-200x200-6'\n",
    "\n",
    "width = height = 200\n",
    "\n",
    "cwd = os.getcwd()\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_path = os.path.join(save_dir, model_dir)\n",
    "\n",
    "#... Load model and weights\n",
    "model = load_model(os.path.join(model_path, 'model.h5'))\n",
    "print('Loaded trained model from %s ' % model_path)\n",
    "\n",
    "with open(os.path.join(model_path, 'label_map.pk'), 'rb') as f:\n",
    "    label_map = pickle.load(f)\n",
    "label_map = {v: k for k, v in label_map.items()}\n",
    "print('Loaded label map...')\n",
    "\n",
    "num_correct = num_wrong = 0\n",
    "\n",
    "images = []\n",
    "addr_list = os.listdir(image_dir)\n",
    "\n",
    "for addr in addr_list:\n",
    "    objs = [addr+'/' + s for s in os.listdir(os.path.join(image_dir, addr))]\n",
    "    images += objs\n",
    "\n",
    "shuffle(images)\n",
    "\n",
    "gtruths = [s.split('/')[-2] for s in images]\n",
    "\n",
    "for i in range(0,100):\n",
    "    \n",
    "    image_file = images[i]\n",
    "    gtruth     = gtruths[i]\n",
    "        \n",
    "    image = Image.open(os.path.join(image_dir, image_file)).convert(\"RGB\").resize((width, height))\n",
    "\n",
    "    img = np.array(image)\n",
    "#     img = img / 255.0\n",
    "    \n",
    "    r = img[:,:,0]\n",
    "    g = img[:,:,1]\n",
    "    b = img[:,:,2]\n",
    "\n",
    "    npimage = np.array([[r] + [g] + [b]], np.uint8)\n",
    "    npimage = npimage.transpose(0,2,3,1)\n",
    "\n",
    "    classes = model.predict_classes(npimage)\n",
    "    pred = model.predict(npimage, verbose=2)\n",
    "    \n",
    "    if label_map[classes[0]] == gtruth:\n",
    "        num_correct += 1\n",
    "    else:\n",
    "        num_wrong += 1\n",
    "    \n",
    "#     print(pred.argmax(), classes[0], label_map[classes[0]], gtruth, image_file)\n",
    "#     plt.imshow(img)\n",
    "\n",
    "print ('Right = ' + str(num_correct/(num_correct+num_wrong)*100.0) + '\\n' +\n",
    "       'Wrong = ' + str(num_wrong/(num_correct+num_wrong)*100.0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python354",
   "language": "python",
   "name": "python354"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
