{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### %reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import ast\n",
    "import csv\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import keras\n",
    "    \n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "    \n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import History \n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "import mountainproject as mp\n",
    "\n",
    "from importlib import reload\n",
    "reload(mp)\n",
    "\n",
    "# Allow image embeding in notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--aug', '-a', default=False)\n",
    "parser.add_argument('--batchsize', '-b', default=32)\n",
    "parser.add_argument('--height', '-y')\n",
    "parser.add_argument('--imagedir', '-i')\n",
    "parser.add_argument('--learningrate', '-l', default=1e-6)\n",
    "parser.add_argument('--numimages', '-n')\n",
    "parser.add_argument('--opt', '-o')\n",
    "parser.add_argument('--uniqueid', '-u', default=0)\n",
    "parser.add_argument('--width', '-x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().__class__.__name__\n",
    "    args = parser.parse_args(['-x 100', '-y 100', '-o=Adam', \n",
    "                              '-a=False', '-u 4'])\n",
    "    print('In Jupyter...')\n",
    "except:\n",
    "    args = parser.parse_args()\n",
    "    print('NOT in Jupyter...')\n",
    "    \n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = args.aug\n",
    "batch_size        = int(args.batchsize)\n",
    "image_height      = int(args.height)\n",
    "image_dir         = os.path.join(os.getcwd(), args.imagedir)\n",
    "lr                = float(args.learningrate)\n",
    "opt               = args.opt\n",
    "unique_id         = int(args.uniqueid)\n",
    "image_width       = int(args.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_dir      = '/home/joeantol/work/project-x/data/21st-street/trainval/'\n",
    "training_dir   = os.path.join(image_dir, 'training')\n",
    "validation_dir = os.path.join(image_dir, 'validation')\n",
    "\n",
    "# training_dir   = '/home/joeantol/work/project-x/data/gopro/21st-street'\n",
    "# validation_dir = '/home/joeantol/work/project-x/data/android/21st-street'\n",
    "\n",
    "classes = []\n",
    "\n",
    "for d in os.listdir(training_dir):\n",
    "    if os.path.isdir(os.path.join(training_dir, d)):\n",
    "        classes.append(d)\n",
    "        \n",
    "# print(\"Image dir: \" + image_dir)\n",
    "print(\"Training dir: \" + training_dir)\n",
    "print(\"Validation dir: \" + validation_dir)\n",
    "print(\"Classes: \" + str(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 0\n",
    "\n",
    "for dirs, subdirs, files in os.walk(training_dir):\n",
    "    for file in files:\n",
    "        num_images += 1\n",
    "\n",
    "for dirs, subdirs, files in os.walk(validation_dir):\n",
    "    for file in files:\n",
    "        num_images += 1\n",
    "\n",
    "print('Number of images: ' + str(num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 500\n",
    "\n",
    "cwd = os.getcwd()\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_path = os.path.join(save_dir, '21stStreet' + '-' + opt + '-' + str(num_images) + '-' \n",
    "                          + str(image_width) + 'x' + str(image_height) + '-' + str(unique_id))\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "print('Saving model at: '+ model_path)\n",
    "\n",
    "mp.set_reproducable_results(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... Create a bunch of optimizer objects for later use\n",
    "sgd = keras.optimizers.SGD(lr=lr, momentum=0.0, decay=0.001, nesterov=False)\n",
    "RMSprop = keras.optimizers.RMSprop(lr=lr, rho=0.9, epsilon=1e-6, decay=0.001)\n",
    "Adam = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-6, decay=0.001)\n",
    "\n",
    "opts = {'Adam'    : Adam,\n",
    "        'RMSprop' : RMSprop,\n",
    "        'SGD'     : sgd\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Build the model...\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "filters = 32\n",
    "model.add(Conv2D(filters, (3, 3), padding='same', input_shape=(image_width, image_height, 3)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters*2, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters*2, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(filters*16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(classes)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compiling...\")\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opts[opt],\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create training and validation generators...\")\n",
    "\n",
    "#... Per Stanford,we want to zero-mean, but not normalize variance or do PCA or whitening\n",
    "if data_augmentation:\n",
    "    print(\"Using data augmentation...\")\n",
    "    train_datagen = ImageDataGenerator(\n",
    "                                       ###rescale = 1./255,\n",
    "                                       rotation_range = 30,\n",
    "                                       width_shift_range = 0.3,\n",
    "                                       height_shift_range = 0.3,\n",
    "                                       zoom_range = 0.25,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True\n",
    "                                      )\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "                                       ###rescale=1./255\n",
    "                                      )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                  ###rescale=1./255\n",
    "                                 )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size=(image_width, image_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        follow_links=True\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(image_width, image_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        follow_links=True\n",
    ")\n",
    "\n",
    "label_map = (train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.samples//batch_size + 1, validation_generator.samples//batch_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train the model...\")\n",
    "\n",
    "hist = History()\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=20, verbose=2, mode='auto')\n",
    "time_callback = mp.TimeHistory()\n",
    "lambda_callback = LambdaCallback(on_batch_end=lambda batch,logs:print(logs))\n",
    "\n",
    "checkpoint_file = os.path.join(model_path, 'model.{epoch:02d}-{val_acc:.2f}.hdf5')\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_file, monitor='val_acc', verbose=1, save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples//batch_size + 1,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples//batch_size + 1,\n",
    "        use_multiprocessing=True,\n",
    "        workers=8,\n",
    "        callbacks=[early_stopping, time_callback, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... Save model and weights\n",
    "model.save(os.path.join(model_path, 'model.h5'))\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "#... Save history\n",
    "with open(os.path.join(model_path, 'history.pk'), 'wb') as f:\n",
    "    pickle.dump(hist.history, f)\n",
    "print('Saved history at %s ' % model_path)\n",
    "\n",
    "#... Save epoch times\n",
    "with open(os.path.join(model_path, 'times.pk'), 'wb') as f:\n",
    "    pickle.dump(time_callback.times, f)\n",
    "print('Saved epoch times at %s ' % model_path)\n",
    "\n",
    "#... Score trained model.\n",
    "# predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "pred = model.predict_generator(validation_generator, workers=8, use_multiprocessing=True, verbose=1)\n",
    "with open(os.path.join(model_path, 'pred.pk'), 'wb') as f:\n",
    "    pickle.dump(pred, f)\n",
    "print('Saved predictions at %s ' % model_path)\n",
    "\n",
    "eval_scores = model.evaluate_generator(validation_generator, workers=8, use_multiprocessing=True)\n",
    "with open(os.path.join(model_path, 'eval.pk'), 'wb') as f:\n",
    "    pickle.dump(eval_scores, f)\n",
    "print('Saved eval at %s ' % model_path)\n",
    "\n",
    "with open(os.path.join(model_path, 'label_map.pk'), 'wb') as f:\n",
    "    pickle.dump(label_map, f)\n",
    "print('Saved label map at %s ' % model_path)\n",
    "\n",
    "print('Test loss:', eval_scores[0])\n",
    "print('Test accuracy:', eval_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... TODO: Confustion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Successful completion of Buildings-1...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python363",
   "language": "python",
   "name": "python363"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
