{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "sys.version\n",
    "\n",
    "import argparse\n",
    "import ast\n",
    "import csv\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import keras\n",
    "    \n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from keras.applications.xception import Xception, preprocess_input, decode_predictions\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions\n",
    "    \n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import History \n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "import convnet_image_utils\n",
    "from importlib import reload\n",
    "reload(convnet_image_utils)\n",
    "from convnet_image_utils import ProjectX\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Allow image embeding in notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_model(input_model, opt, num_classes, shape=(224,224,3), verbose=False):\n",
    "        \n",
    "    if verbose: input_model.summary()\n",
    "        \n",
    "    x = input_model.layers[-2].output\n",
    "\n",
    "    predictions = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=input_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in input_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    if verbose: model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model, num_classes):\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "    \n",
    "    predictions = Dense(num_classes, activation='softmax')(x) #new softmax layer\n",
    "\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_vgg16(verbose=False, shape=(224,224,3)):\n",
    "    \n",
    "    image_input = Input(shape=shape)\n",
    "\n",
    "    model = VGG16(input_tensor=image_input, include_top=True, weights='imagenet')\n",
    "\n",
    "    if verbose: model.summary()\n",
    "\n",
    "    last_layer = model.get_layer('block5_pool').output\n",
    "    \n",
    "    x= Flatten(name='flatten')(last_layer)\n",
    "    x = Dense(128, activation='relu', name='fc1')(x)\n",
    "    x = Dense(128, activation='relu', name='fc2')(x)\n",
    "    out = Dense(len(X.classes), activation='softmax', name='output')(x)\n",
    "    \n",
    "    custom_vgg_model = Model(image_input, out)\n",
    "    \n",
    "    if verbose: custom_vgg_model.summary()\n",
    "\n",
    "    #... Freeze all the layers except the dense layers\n",
    "    for layer in custom_vgg_model.layers[:-3]:\n",
    "            layer.trainable = False\n",
    "\n",
    "    if verbose: custom_vgg_model.summary()\n",
    "\n",
    "    custom_vgg_model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "    \n",
    "    return custom_vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... Fine tune the resnet 50  \n",
    "def fine_tune_resnet(verbose=False):\n",
    "    \n",
    "    image_input = Input(shape=(X.image_width, X.image_height, 3))\n",
    "    model = ResNet50(weights='imagenet',include_top=False)\n",
    "    \n",
    "    if verbose: model.summary()\n",
    "    \n",
    "    last_layer = model.output\n",
    "\n",
    "    #... Add a global spatial average pooling layer\n",
    "    x = GlobalAveragePooling2D()(last_layer)\n",
    "\n",
    "    #... Add fully-connected & dropout layers\n",
    "    x = Dense(512, activation='relu',name='fc-1')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu',name='fc-2')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    out = Dense(len(X.classes), activation='softmax',name='output_layer')(x)\n",
    "\n",
    "    #... This is the model we will train\n",
    "    custom_resnet_model = Model(inputs=model.input, outputs=out)\n",
    "\n",
    "    if verbose: custom_resnet_model.summary()\n",
    "\n",
    "    for layer in custom_resnet_model.layers[:-6]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    custom_resnet_model.layers[-1].trainable\n",
    "\n",
    "    custom_resnet_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return custom_resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_resnet_classifier_alone(verbose=False):\n",
    "\n",
    "    image_input = Input(shape=(X.image_height, X.image_width, 3))\n",
    "    model = ResNet50(input_tensor=image_input, include_top=True, weights='imagenet')\n",
    "    \n",
    "    if verbose: model.summary()\n",
    "\n",
    "    last_layer = model.get_layer('avg_pool').output\n",
    "    x = Flatten(name='flatten')(last_layer)\n",
    "    out = Dense(len(X.classes), activation='softmax', name='output_layer')(x)\n",
    "\n",
    "    custom_resnet_model = Model(inputs=image_input, outputs=out)\n",
    "    \n",
    "    if verbose: custom_resnet_model.summary()\n",
    "\n",
    "    for layer in custom_resnet_model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    custom_resnet_model.layers[-1].trainable\n",
    "\n",
    "    custom_resnet_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    return custom_resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_data_generator (X):\n",
    "    \n",
    "#     preproc_func = X.normalize\n",
    "\n",
    "    #... Use pre-proc function from Keras\n",
    "    preproc_func = preprocess_input\n",
    "    \n",
    "    #... Per Stanford,we want to zero-mean, but not normalize variance or do PCA or whitening\n",
    "    if X.data_augmentation:\n",
    "        print(\"Using data augmentation...\")\n",
    "        train_datagen = ImageDataGenerator(\n",
    "                                           rotation_range = 30,\n",
    "                                           width_shift_range = 0.3,\n",
    "                                           height_shift_range = 0.3,\n",
    "                                           zoom_range = 0.25,\n",
    "                                           horizontal_flip=True,\n",
    "                                           vertical_flip=True,\n",
    "                                           featurewise_center=False,\n",
    "                                           featurewise_std_normalization=False,\n",
    "                                           preprocessing_function = preproc_func,\n",
    "\n",
    "                                          )\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(preprocessing_function = preproc_func,)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function = preproc_func,)\n",
    "    \n",
    "    return train_datagen, test_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... Create a bunch of optimizer objects for later use\n",
    "def optimizers(lr):\n",
    "\n",
    "    sgd = keras.optimizers.SGD(lr=lr, momentum=0.0, decay=0.001, nesterov=False)\n",
    "    RMSprop = keras.optimizers.RMSprop(lr=lr, rho=0.9, epsilon=1e-6, decay=0.001)\n",
    "    Adam = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-6, decay=0.001)\n",
    "\n",
    "    opts = {'Adam'    : Adam,\n",
    "            'RMSprop' : RMSprop,\n",
    "            'SGD'     : sgd\n",
    "           }\n",
    "    \n",
    "    return opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    args = ['-x=224', '-y=224', '-i=data/union/gunks/trapps/trainval', '-u=112', '-l=1e-4', \n",
    "            '-p=transfer_learning_union_VGG16']\n",
    "    \n",
    "    try:\n",
    "        logfile_name = os.path.splitext(__file__)[0]\n",
    "        program_name = __file__\n",
    "    except:\n",
    "        logfile_name='projectx'\n",
    "        program_name = 'climbatron-1.py'\n",
    "\n",
    "    X = ProjectX(logfile_name=logfile_name)\n",
    "\n",
    "    X.args(args)\n",
    "    X.get_classes_from_dirs()\n",
    "    X.create_model_dir(program_name=program_name)\n",
    "    \n",
    "    #... Make sure we only read and/or calculate once\n",
    "    X.mean, X.std = X.sample_mean_and_std(batch_size=500)\n",
    "\n",
    "    opts = optimizers(X.lr)\n",
    "    \n",
    "    train_datagen, val_datagen = image_data_generator(X)\n",
    "\n",
    "    train_gen = X.create_generators(train_datagen, os.path.join(X.image_dir, 'training'))\n",
    "    val_gen   = X.create_generators(val_datagen, os.path.join(X.image_dir, 'validation'))\n",
    "    \n",
    "    model_args = {'include_top' : False, 'weights' : 'imagenet'}\n",
    "    base_model = VGG16(model_args)\n",
    "    \n",
    "    model = add_new_last_layer(base_model, X.num_classes)\n",
    "\n",
    "#     model = pretrained_model(input_model, opts['Adam'], train_gen.num_classes, verbose=True)\n",
    "\n",
    "#     X.train_the_model(model, train_gen, val_gen, epochs=X.epochs)\n",
    "#     X.save_the_model(model, val_gen)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_loop():\n",
    "    args = ['-x=224', '-y=224', '-i=data/union/gunks/trapps/trainval', '-u=111', '-l=1e-4', \n",
    "            '-p=transfer_learning_union']\n",
    "    \n",
    "    try:\n",
    "        logfile_name = os.path.splitext(__file__)[0]\n",
    "        program_name = __file__\n",
    "    except:\n",
    "        logfile_name='projectx'\n",
    "        program_name = 'climbatron-1.py'\n",
    "\n",
    "    X = ProjectX(logfile_name=logfile_name)\n",
    "\n",
    "    X.args(args)\n",
    "    X.get_classes_from_dirs()\n",
    "    \n",
    "    #... Make sure we only read and/or calculate once\n",
    "    X.mean, X.std = X.sample_mean_and_std(batch_size=500)\n",
    "\n",
    "    opts = optimizers(X.lr)\n",
    "\n",
    "    train_datagen, val_datagen = image_data_generator(X)\n",
    "\n",
    "    train_gen = X.create_generators(train_datagen, os.path.join(X.image_dir, 'training'))\n",
    "    val_gen   = X.create_generators(val_datagen, os.path.join(X.image_dir, 'validation'))\n",
    "    \n",
    "    project_name = X.project_name\n",
    "    \n",
    "    model_args = {'include_top' : False, \n",
    "                  'weights'     : 'imagenet', \n",
    "                  'input_shape' : (X.image_width, X.image_height, 3)\n",
    "                 }\n",
    "    \n",
    "    base_models = {\n",
    "              'InceptionResNetV2' : InceptionResNetV2(model_args),\n",
    "              'InceptionV3'       : InceptionV3(model_args),\n",
    "              'Xception'          : Xception(model_args),\n",
    "              'MobileNet'         : MobileNet(model_args),\n",
    "              'VGG16'             : VGG16(model_args),\n",
    "              'VGG19'             : VGG19(model_args),    \n",
    "              'ResNet50'          : ResNet50(model_args),\n",
    "             }\n",
    "\n",
    "    for m_name in models:\n",
    "\n",
    "        X.project_name = project_name + '_' + m_name\n",
    "        X.create_model_dir(program_name=program_name)\n",
    "\n",
    "        model = pretrained_model(models[m_name], opts['Adam'], train_gen.num_classes, verbose=True)\n",
    "\n",
    "        X.train_the_model(model, train_gen, val_gen, epochs=X.epochs)\n",
    "        X.save_the_model(model, val_gen)\n",
    "        \n",
    "        print(\"Successful completion of \" + m_name +  \"...\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {'include_top' : False, \n",
    "              'weights'     : 'imagenet', \n",
    "              'input_shape' : (224,224,3)}\n",
    "\n",
    "base_models = {\n",
    "          'InceptionResNetV2' : InceptionResNetV2(model_args),\n",
    "          'InceptionV3'       : InceptionV3(model_args),\n",
    "          'Xception'          : Xception(model_args),\n",
    "#           'MobileNet'         : MobileNet(model_args),\n",
    "          'VGG16'             : VGG16(model_args),\n",
    "          'VGG19'             : VGG19(model_args),    \n",
    "          'ResNet50'          : ResNet50(model_args),\n",
    "         }\n",
    "\n",
    "for m_name in base_models:\n",
    "    print(m_name)\n",
    "\n",
    "    base_model = base_models[m_name]\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(int(x.shape[-1]), activation='relu')(x) \n",
    "    predictions = Dense(47, activation='softmax')(x) \n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    print(model.name)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "#     main_loop()\n",
    "    \n",
    "    print(\"Successful completion of climbatron-1 ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
