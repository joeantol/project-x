{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joeantol/python-envs/python363/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/joeantol/python-envs/python363/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import callbacks\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random as rn\n",
    "import skimage.data\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Allow image embeding in notebook\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_this_function(msg = None):\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_building_data(image_dir, label_file, num_images=1e100, dim=(100,100)):\n",
    "    \n",
    "    import csv\n",
    "    import os\n",
    "    import random\n",
    "    import skimage.data\n",
    "    import numpy as np\n",
    "    \n",
    "    from PIL import Image\n",
    "    \n",
    "    \"\"\"Loads a data set and returns three lists:\n",
    "    \n",
    "    images: a list of Numpy arrays, each representing an image.\n",
    "    labels: a list of numbers that represent the images labels.\n",
    "    xref: a list of names that cross refs to label numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    labels     = []\n",
    "    images     = []\n",
    "    label_data = []\n",
    "    \n",
    "    i         = 0\n",
    "    address   = None\n",
    "    cur_label = None\n",
    "     \n",
    "    xref, label_data = load_xref(label_file)\n",
    "    \n",
    "    #... Create empty arrays (faster than appending)\n",
    "    npimages = np.zeros(shape=(num_images+1, dim[0], dim[1], 3))\n",
    "    nplabels = np.zeros(shape=(num_images+1))\n",
    "            \n",
    "    for rec in label_data:\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        _, image_file = rec[0].split('-')\n",
    "        label = rec[2]\n",
    "        \n",
    "        image_file = os.path.join(image_dir, image_file)\n",
    "                \n",
    "        if os.path.isfile(image_file): \n",
    "                        \n",
    "            image = skimage.data.imread(image_file)\n",
    "        \n",
    "            if address != rec[1]:\n",
    "                address = rec[1]\n",
    "                xref.append(address)\n",
    "            \n",
    "            try:\n",
    "                if address != cur_label:\n",
    "                    print('Processing images for ' + address )\n",
    "                    cur_label = address\n",
    "                    \n",
    "                if i % 100 == 0:\n",
    "                    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "                    print( '   Loading[' + str(i) + ']: ' + image_file )\n",
    "\n",
    "                img = np.array( Image.fromarray(image, 'RGB').resize(dim) )\n",
    "\n",
    "                r = img[:,:,0]\n",
    "                g = img[:,:,1]\n",
    "                b = img[:,:,2]\n",
    "\n",
    "                if i == 0:\n",
    "                    npimage = np.array([[r] + [g] + [b]], np.uint8)\n",
    "                    npimages[i] = npimage.transpose(0,2,3,1)\n",
    "                    \n",
    "                    nplabels[i] = np.array([label], np.uint8)\n",
    "\n",
    "                new_array = np.array([[r] + [g] + [b]], np.uint8)\n",
    "                new_array = new_array.transpose(0,2,3,1)\n",
    "#                 npimages  = np.append(npimages, new_array, 0) \n",
    "                npimages[i] = new_array\n",
    "\n",
    "                new_label = np.array([label], np.uint8)\n",
    "#                 nplabels = np.append(nplabels, new_label, 0)\n",
    "                nplabels[i] = new_label\n",
    "\n",
    "            except ValueError as e:  #... Need to fix so only catch 'not enough data' error\n",
    "                print(str(e))\n",
    "                break\n",
    "#                 print(' >>>> WARNING: Cannot process image for ' + xref[nplabels[i]] \n",
    "#                       + ' ' + str(e) + ' <<<<')\n",
    "\n",
    "            i += 1\n",
    "                    \n",
    "        #... For testing\n",
    "        if i > num_images:\n",
    "            break\n",
    "            \n",
    "    return npimages, nplabels, xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_xref(image_file):\n",
    "    import os\n",
    "    import csv\n",
    "    \n",
    "    xref       = []\n",
    "    label_data = []\n",
    "\n",
    "    print('Loading cross reference data from ' + image_file + '...')\n",
    "\n",
    "    with open(image_file, 'r') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        next(csv_reader)\n",
    "        label_data = list(csv_reader)\n",
    "\n",
    "        for i in [row[1] for row in label_data]:\n",
    "            if i not in xref:\n",
    "                xref.append(i)\n",
    "                \n",
    "    return xref, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/keras-team/keras/issues/2280#issuecomment-306959926\n",
    "# https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "\n",
    "def set_reproducable_results(reproducable_results=True):\n",
    "\n",
    "    if reproducable_results:\n",
    "        os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "        # The below is necessary for starting Numpy generated random numbers\n",
    "        # in a well-defined initial state.\n",
    "\n",
    "        np.random.seed(42)\n",
    "\n",
    "        # The below is necessary for starting core Python generated random numbers\n",
    "        # in a well-defined state.\n",
    "\n",
    "        rn.seed(12345)\n",
    "\n",
    "        # Force TensorFlow to use single thread.\n",
    "        # Multiple threads are a potential source of\n",
    "        # non-reproducible results.\n",
    "        # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "        session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "        from keras import backend as K\n",
    "\n",
    "        # The below tf.set_random_seed() will make random number generation\n",
    "        # in the TensorFlow backend have a well-defined initial state.\n",
    "        # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "        tf.set_random_seed(1234)\n",
    "\n",
    "        sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "        K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    \"\"\"Loads a data set and returns three lists:\n",
    "    \n",
    "    images: a list of Numpy arrays, each representing an image.\n",
    "    labels: a list of numbers that represent the images labels.\n",
    "    labels_xref: a list of names that cross refs to label numbers\n",
    "    \"\"\"\n",
    "\n",
    "    labels = []\n",
    "    images = []\n",
    "    labels_xref = []\n",
    "    label_num = 0\n",
    "\n",
    "    dirs = os.listdir(data_dir)\n",
    "\n",
    "    for climb_name in dirs:\n",
    "        \n",
    "        image_dir = os.path.join(data_dir, climb_name)\n",
    "        \n",
    "        if climb_name == '.done':\n",
    "            continue\n",
    "        \n",
    "        #... Skip climbs w/ no images\n",
    "        if os.listdir(image_dir) == []:\n",
    "            continue\n",
    "\n",
    "        labels_xref.append(climb_name)\n",
    "\n",
    "        for image in os.listdir(image_dir):\n",
    "\n",
    "            print(\"Loading[\" + str(label_num) + ']: ', os.path.join(image_dir, image))\n",
    "            labels.append(label_num)\n",
    "            images.append(skimage.data.imread(os.path.join(image_dir, image)))\n",
    "            \n",
    "        label_num += 1\n",
    "            \n",
    "    return images, labels, labels_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_cifar(images, labels, labels_xref, dim=(100,100)):\n",
    "\n",
    "    cur_label = None\n",
    "        \n",
    "    for i in range(len(images)):\n",
    "                \n",
    "        try:\n",
    "            if labels_xref[labels[i]] != cur_label:\n",
    "                print('Processing images for ' + labels_xref[labels[i]] )\n",
    "                cur_label = labels_xref[labels[i]]\n",
    "                \n",
    "            img = np.array( Image.fromarray(images[i], 'RGB').resize(dim) )\n",
    "            \n",
    "            r = img[:,:,0]\n",
    "            g = img[:,:,1]\n",
    "            b = img[:,:,2]\n",
    "\n",
    "            if i == 0:\n",
    "                npimages = np.array([[r] + [g] + [b]], np.uint8)\n",
    "                npimages = npimages.transpose(0,2,3,1)\n",
    "                nplabels = np.array([labels[i]], np.uint8)\n",
    "\n",
    "            new_array = np.array([[r] + [g] + [b]], np.uint8)\n",
    "            new_array = new_array.transpose(0,2,3,1)\n",
    "            npimages = np.append(npimages, new_array, 0) \n",
    "            \n",
    "            new_label = np.array([labels[i]], np.uint8)\n",
    "            nplabels = np.append(nplabels, new_label, 0)\n",
    "            \n",
    "        except ValueError as e:  #... Need to fix so only catch 'not enough data' error\n",
    "            print(' >>>> WARNING: Cannot process image for ' + labels_xref[labels[i]] + ' ' + str(e) + ' <<<<')\n",
    "                              \n",
    "    return npimages, nplabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_images_and_labels(images, labels, labels_xref):\n",
    "    \"\"\"Display the first image of each label.\"\"\"\n",
    "    unique_labels = set(labels)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    i = 1\n",
    "    for label in unique_labels:\n",
    "        \n",
    "        #... Pick the first image for each label.\n",
    "        image = images[labels.index(label)]\n",
    "        \n",
    "        #... \n",
    "        plt.subplot(5, 5, i)  # A grid of 8 rows x 8 columns\n",
    "        plt.axis('off')\n",
    "        ###plt.title(\"Label {0} ({1})\".format(label, labels.count(label)))\n",
    "        plt.title(\"({1} [{0}])\".format(label, labels_xref[labels.count(label)]))\n",
    "        i += 1\n",
    "        _ = plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python363",
   "language": "python",
   "name": "python363"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
